## Deep Learning In NLP

NLP中基础的深度学习模型，代码+论文。[参考链接1](https://github.com/graykode/nlp-tutorial)，[参考链接2](https://github.com/DSKSD/DeepNLP-models-Pytorch)

1. code: [nnlm](./code/NNLM.py) , paper:[A Neural Probabilistic Language Model](./papers/nnlm.pdf)
2. code: [word2vec(skipgram)](./code/word2vec_skipgram.py) , paper:[Distributed Representations of Words and Phrases  and their Compositionality](./papers/word2vec.pdf)
3. code: [Glove](./code/Glove.py) , paper:[GloVe:Global Vectors for Word Representation](./papers/glove.pdf)
4. code: [fasttext](./code/FastText.py) , paper:[Bag of Tricks for Efficient Text Classification](./papers/fasttext.pdf)
5. code: [TextCNN](./code/TextCNN.py) , paper:[Convolutional Neural Networks for Sentence Classification](./papers/textCnn.pdf)
6. code: [TextRNN](./code/TextRNN.py) , paper:[Finding Structure in Time](./papers/rnn.pdf)
7. code: [LSTM](./code/TextLSTM.py) , [BiLSTM](./code/BiLSTM.py) , [BiLSTM(Attention)](./code/BiLSTM(Attention).py) paper:[Long Short-Term Memory](./papers/lstm.pdf)
8. code:[Seq2Seq](./code/Seq2Seq.py), [Seq2Seq(Attention)](./code/BiLSTM(Attention).py), paper: [Neural Machine Translation by Jointly Learning to Align and Translate](./papers/seq2seq.pdf)
9. code:[Transformer](./code/Transformer.py),paper:[Attention IS All You Need](attention.pdf)
10. code: [Bert](Bert.py), paper: [BERT: Pre-training of Deep Bidirectioanl Transformers for Language Understanding](./papers/bert.pdf)

